import { Meta } from '@storybook/addon-docs/blocks';

<Meta title="Testing/Component Tests" />

# Component-Level Tests (`test/wdio`)

-   **Purpose:** To test the functionality of individual components or features in perfect isolation. These are our "unit tests" for component behavior.
-   **Technology:** WebdriverIO (WDIO) is the primary framework, utilizing the `@wdio/browser-runner/stencil` for efficient in-browser component rendering and interaction.
-   **Scope:**
    -   Focus on a single feature or permutation at a time. For example, when testing `@Prop({ reflect: true })`, there should be separate, isolated tests for `boolean`, `number`, `string`, `Array`, `Object`, and `Set` types.
    -   Each test should use its own dedicated component to ensure no interference from other properties or features. This is critical for compatibility with our static analysis tools, which rely on finding these features in isolation.
-   **Benefits:**
    -   **Precision:** Tests are clear, targeted, and unambiguous.
    -   **Debugging:** Failures are easy to pinpoint to a specific feature.
    -   **Robustness:** Guarantees that each feature works correctly on its own, forming a reliable foundation.
    -   **Tooling Compatibility:** This approach works well with static analysis-based coverage tools.

## File Naming and Location Conventions

-   **Test Directory:** All component-level tests are located in the `test/wdio` directory. Do not place these tests in the `src/components` directory.
-   **Component Suffix:** Test components must have a `-cmp` suffix in their filename (e.g., `my-feature-cmp.tsx`).
-   **Test File:** The test file for a component or a group of related components should be named `cmp.test.tsx`.

## Writing and Running Component Tests

This guide outlines the complete workflow for creating and executing component-level tests in the `test/wdio` directory. Following these steps will help you contribute effectively to the project's test suite.

### Step 1: Establish a Baseline with the Coverage Script

Before writing any new tests, it's important to understand the current test coverage. The coverage script helps you determine if components exist for all required permutations. For more details, refer to the matrix Generation documentation.

To run the coverage script, use the following command:

```bash
cd test/storybook && npm run coverage
```

This command will analyze the existing test suite and generate a report, giving you a clear picture of where new test components are needed for full permutation coverage.

### Step 2: Generate Test Components

Once you've identified the missing test cases, the next step is to create the necessary test components. These components should be placed in the `test/wdio` directory and follow the established naming conventions.

### Step 3: Build the Test Components

After creating or modifying your test components, you need to build them. Navigate to the `wdio` test directory and run the build command:

```bash
cd test/wdio
npm run build
```

### Step 4: Write the Tests

With the components built, you can now write the tests. These tests should also be located in the `test/wdio` directory and should be written to verify the functionality of the components you've just created.

### Step 5: Run the Tests

To run the tests and ensure they pass, follow these steps:

1.  **Update the test configuration**: Open the `wdio.conf.ts` file and modify the `specs` array to point to your test file(s).
    
    For running a single test:
    ```typescript
    // ...
    specs: [['./state/**/*.test.tsx']],
    // ...
    ```
    
    For running a full suite of tests (e.g., all tests for a decorator), you can use a glob pattern:
    ```typescript
    // ...
    specs: [['./**/*.test.tsx']],
    // ...
    ```

2.  **Run the tests from the `test/wdio` directory**:
    ```bash
    npm run wdio
    ```

This will execute your tests and provide feedback on whether they pass or fail.

### Step 6: Document Learnings

After achieving 100% coverage for a feature, the final step is to document the key learnings from the iteration. This is a crucial part of our self-improving testing loop. For a complete guide on what to document and where, please refer to the "Continuous Improvement" section of the main [Testing Strategy](./testing_strategy.md) document.

## Best Practices

### Testing State Mutations

When testing how a component's state changes (e.g., when a `@Prop({ mutable: true })` is modified), it's crucial to verify the component's behavior before and after the change. A reliable pattern for this is:

1.  **Initial State Assertion:** Verify the initial state of the component's property.
2.  **User-like Interaction:** Trigger an action that should cause the state to change. This is typically a click on a button or another user-driven event.
3.  **Final State Assertion:** Verify that the property has been updated to the new, expected value.

This "before and after" approach ensures that the mutation is a direct result of the interaction and that the component behaves as expected.

### Testing Event Emissions

When testing `@Event` decorators, the most reliable and direct pattern is to use an in-component `@Listen` decorator to verify that the event was emitted. This avoids the complexities and potential flakiness of trying to intercept events from outside the component.

**Example:**

A component that emits a `testEvent` can have a simple counter that is incremented by a `@Listen('testEvent')` handler. The test then only needs to check if the counter's value has been updated.

**Component (`event-basic-cmp.tsx`):**

```tsx
import { Component, Event, EventEmitter, h, Listen, State } from '@stencil/core';

@Component({ tag: 'event-basic' })
export class EventBasic {
  @Event() testEvent: EventEmitter;
  @State() counter = 0;

  @Listen('testEvent')
  testEventHandler() {
    this.counter++;
  }

  render() {
    return (
      <button onClick={() => this.testEvent.emit()}>Emit Event</button>
      <p>Emission count: <span id="counter">{this.counter}</span></p>
    );
  }
}
```

**Test (`cmp.test.tsx`):**

```tsx
import { h } from '@stencil/core';
import { render } from '@wdio/browser-runner/stencil';

describe('event-basic', () => {
  beforeEach(async () => {
    render({
      template: () => <event-basic></event-basic>,
    });
  });

  it('should increment counter when event is emitted', async () => {
    await expect($('#counter')).toHaveText('0');
    await $('button').click();
    await expect($('#counter')).toHaveText('1');
  });
});
```

This pattern is simple, robust, and aligns with Stencil's architecture, making it the preferred method for testing event emissions.
