import { Meta } from '@storybook/addon-docs/blocks';

<Meta title="Testing/Audit" />

# Testing Strategy Audit Log

This document tracks the progress and effectiveness of the GenAI-powered testing strategy over time. Each entry represents a significant iteration or application of the strategy to a specific feature set.

---

## Iteration 1: `@Prop` Decorator

**Date:** August 19, 2025

### Phase 1: Initial Coverage Push

-   **Target Feature:** `@Prop` decorator.
-   **Initial Focus:** Permutations of the `type` and `reflect` properties.
-   **Action:** Utilized the GenAI-powered loop to generate component-level tests (`test/wdio`) for all identified permutations.
-   **Outcome:** The coverage script reported **100% coverage** for the known permutations. The testing strategy appeared to be a complete success.

### Phase 2: Discovery of a Blind Spot

-   **Action:** A manual review of the `@Prop` feature set revealed that the `mutable` property was not included in our permutation matrix or the coverage analysis script.
-   **Impact:** The initial 100% coverage metric was misleading. It only reflected the permutations we were aware of, not the complete feature set.
-   **Outcome:** The `prop-coverage.js` script was updated to recognize the `mutable` property. This immediately doubled the total number of permutations, causing the coverage metric to plummet from **100% to 62.5%**.

### Phase 3: Addressing the Coverage Gap

-   **Action:** Re-engaged the GenAI-powered testing loop with the updated and more accurate permutation matrix. The AI assistant generated a new suite of tests specifically targeting the `mutable` permutations.
-   **Outcome:** The new tests successfully covered the missing permutations, bringing the total coverage for the `@Prop` decorator back to **100%**.

### Key Learnings:

-   The testing loop proved to be self-correcting. When a blind spot was identified and the "source of truth" (the coverage script) was updated, the strategy seamlessly guided the process of filling the gap.
-   Static analysis is a powerful but imperfect tool. It is only as good as the patterns it's configured to find, highlighting the need for periodic human review to identify what might be missing.
-   The exponential cost of comprehensive testing was validated. Adding a single boolean property doubled the testing matrix, reinforcing the need for an efficient and scalable strategy.
-   **Human-AI Collaboration is Key**: This entire process was a partnership. The AI was a powerful engine for generating code and executing the testing loop, but human insight was required to identify the initial blind spot (`mutable`) and refine the strategy. The most effective approach is one that leverages AI for speed and scale while relying on human expertise for critical thinking and direction.

---

## Iteration 2: Refining `@Prop` Mutation Tests

**Date:** August 19, 2025

### Phase 1: Addressing Mutation Test Failures

-   **Target Feature:** `@Prop` decorator with `mutable: true` and `reflect: true`.
-   **Initial State:** While coverage was at 100%, it was discovered that tests for complex types (`Array`, `Object`) were not passing as expected after a mutation.
-   **Action:**
    1.  Investigated the Stencil runtime to identify the root cause of the reflection issue.
    2.  Temporarily modified the tests to expect the buggy behavior, allowing the build to pass while documenting the issue.
    3.  Updated the Storybook documentation to include a "Known Bugs" section, making the issues transparent.
-   **Outcome:** A reliable pattern for testing mutations was established:
    -   Render a component with an initial state.
    -   Verify the initial state and attribute reflection (or lack thereof for known bugs).
    -   Trigger a mutation (e.g., by clicking a button).
    -   Verify the component's state and attribute reflection after the mutation.

### Phase 2: Improving Static Analysis and Documentation

-   **Action:**
    1.  Refined the permutation matrix generation to more accurately capture all `@Prop` variations.
    2.  Discovered that the static analysis script was not correctly identifying all `@Prop` decorators, leading to an inaccurate coverage report.
    3.  Improved the testing strategy documentation to be more modular and easier to navigate.
-   **Outcome:** The static analysis tools and documentation were made more robust, ensuring a more accurate and maintainable testing framework.

### Key Learnings:

-   **Mutation Testing Pattern:** A standardized, reliable pattern for testing mutations was developed and validated.
-   **Static Analysis Refinement:** The process revealed weaknesses in the static analysis script, which were subsequently improved.
-   **Iterative Documentation:** The testing strategy documentation itself is part of the iterative loop and should be updated with new learnings as they emerge.

---

## Iteration 3: `@State` Decorator

**Date:** August 21, 2025

### Phase 1: Initial Test Generation

-   **Target Feature:** `@State` decorator.
-   **Initial Focus:** All permutations of type (`string`, `number`, `boolean`, `array`, `object`, `any`) and default value presence (`true`, `false`).
-   **Action:** Applied the GenAI-powered testing loop to generate component-level tests in `test/wdio/state/` for all 12 identified permutations.
-   **Outcome:** Successfully generated 10 component files and corresponding tests. All tests passed on first execution.

### Phase 2: Coverage Script Issues

-   **Challenge:** Despite generating all necessary components, the coverage script initially reported only 75% coverage, missing 3 permutations:
    - `boolean` with default value (`true`)
    - `object` with default value (`true`) 
    - `object` without default value (`false`)
-   **Root Cause:** The regex pattern in `state-coverage.js` was overly greedy (`[\s\S]*?;`) which caused incorrect parsing of initializers, especially in multi-statement contexts.
-   **Action:** Updated the regex from `/@State\(\)\s+([\w\d_]+)(?::\s*([\w\d\[\]<>{}|.'"]+))?(\s*=\s*[\s\S]*?;)?/g` to `/@State\(\)\s+([\w\d_]+)(?::\s*([\w\d\[\]<>{}|.'"]+))?(\s*=\s*[^;]*;)?/g` to be non-greedy and more precise.
-   **Outcome:** After the regex fix, coverage improved to 91.67% with only the `boolean` with default value still missing.

### Phase 3: Final Coverage Resolution

-   **Challenge:** The script still failed to identify two permutations: `object` without a default value and `any` with a default value.
-   **Root Cause:**
    1.  The test component for `object` without a default value (`state-object-no-default-cmp.tsx`) had an incorrect type annotation (`any` instead of `object`).
    2.  The test component for `any` with a default value (`state-any-default-cmp.tsx`) was missing a type annotation, causing the script to infer the type as `string` from the default value.
-   **Action:**
    1.  Corrected the type annotation in `state-object-no-default-cmp.tsx` to `object`.
    2.  Added the `: any` type annotation to `state-any-default-cmp.tsx`.
-   **Outcome:** After these corrections, the coverage script successfully ran and reported **100% coverage**. All 12 permutations for the `@State` decorator are now fully tested.

### Key Learnings:

-   **Test Generation Success:** The AI successfully generated all required test components and tests on the first attempt, showing improvement in the testing loop efficiency.
-   **Coverage Script Vulnerabilities:** Regex patterns in coverage scripts need careful crafting to avoid false negatives. Greedy patterns can cause incorrect parsing in complex code contexts.
-   **File Placement Accuracy:** All components were correctly placed in the `test/wdio/state/` directory following established naming conventions (`*-cmp.tsx`).
-   **Documentation Workflow Improvements:** The testing workflow documentation was refined to reflect the correct single-step build process (`cd test/wdio && npm run build`) rather than the initially documented two-step process.
-   **Testing Strategy Evolution:** Added the crucial sixth step to the testing loop: "Document Learnings" to ensure continuous improvement between iterations.

### Process Improvements Made:

1. **Updated Testing Strategy Documentation:** Added Step 6 to document learnings and ensure continuous improvement.
2. **Refined Component Test Guide:** Corrected the build process documentation to reflect actual workflow.
3. **Coverage Script Enhancement:** Improved regex patterns for more accurate static analysis.
4. **Workflow Optimization:** Streamlined the testing process based on lessons learned from previous iterations.
5. **Test Configuration Refinement:** Clarified the workflow for managing test execution in `wdio.conf.ts`, advocating for specific paths during debugging and glob patterns for full suite runs.

---

## Iteration 4: `@Event` Decorator

**Date:** August 26, 2025

### Phase 1: Initial Misdirection

-   **Target Feature:** `@Event` decorator.
-   **Initial Action:** The AI assistant was tasked with bringing `@Event` decorator coverage to 100%. However, it immediately went down the wrong path by attempting to generate E2E tests instead of component tests, and placing them in the incorrect directory (`test/end-to-end/` instead of `test/wdio/`).
-   **Correction:** Human intervention was required to redirect the AI, pointing it to the correct `wdio` directory and the `@State` decorator tests as a pattern to follow.

### Phase 2: Test Implementation Failures

-   **Challenge:** The AI struggled to adopt the correct testing pattern. Its first attempt at creating the test file (`cmp.test.tsx`) used `newSpecPage` from Stencil's unit testing framework, which was incorrect for component tests.
-   **Correction:** The user again corrected the AI, pointing out the convention mismatch.
-   **Second Failure:** The AI's next attempt was also flawed. It used a non-existent `browser.spyOn` method, which caused the tests to fail. This led to a frustrating loop where the AI was unable to correct its own mistake.

### Phase 3: File System and Pattern Discovery Issues

-   **Challenge:** The AI entered a persistent failure loop where it was unable to successfully write to the test file (`cmp.test.tsx`). The file repeatedly appeared as empty or corrupted, requiring the user to manually revert changes and suggest workarounds, such as using a temporary file name.
-   **A Better Pattern Revealed:** The most significant issue was the AI's failure to recognize the simplest existing testing pattern. While the AI was attempting a complex and incorrect solution using `browser.execute`, the user pointed out that existing tests (like `event-basic`) used a much cleaner in-component `@Listen` decorator to verify the event emission.
-   **Outcome:** This insight was critical. It rendered the AI's complex solution obsolete and highlighted a major blind spot in its ability to learn from the most relevant examples in the codebase.

### Phase 4: Final Refactoring and Success

-   **Action:** Following the user's guidance, the AI refactored all the newly generated components to use the `@Listen` pattern. The test file (`cmp-tests.tsx`) was simplified to check a counter, aligning with the established, simpler convention.
-   **Outcome:** After adopting the correct pattern as identified by the user, the tests were simplified, and the process was successfully completed.

### Key Learnings:

-   **Pattern Blindness:** This iteration revealed a critical failure in the AI's ability to identify and adopt the best and simplest existing patterns, even when provided with examples. It defaulted to a more complex, generic, and ultimately incorrect solution.
-   **Tool-Level Instability:** The AI exhibited significant instability with basic file operations, leading to a frustrating user experience and requiring manual workarounds. This points to a need for more robust error handling and self-correction in the AI's tool usage.
-   **Over-Reliance on Correction:** The AI was entirely dependent on the user for course correction at every major step. The human's role shifted from supervisor to constant troubleshooter and pattern-matcher.
-   **The Cost of "Almost Right":** The AI's ability to generate code that was syntactically correct but functionally wrong (e.g., using `browser.spyOn`) proved to be a significant time sink, demonstrating that superficial correctness is not a substitute for understanding context and convention.
